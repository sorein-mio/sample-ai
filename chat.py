import streamlit as st
from openai import OpenAI
import time

# ==========================
#  OpenAI APIã‚­ãƒ¼ã®è¨­å®š
# ==========================
client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])  # ã“ã“ã«OpenAIã®APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„

# ==========================
#  ãƒ¢ãƒ‡ãƒ«è¨­å®š
# ==========================
MODELS = {
    "GPT-5 (æœ€å¼·ãƒ»çµ±åˆå‹)": {
        "id": "gpt-5",
        "description": "2025å¹´8æœˆãƒªãƒªãƒ¼ã‚¹ã®æœ€å¼·ãƒ¢ãƒ‡ãƒ«ã€‚GPTã‚·ãƒªãƒ¼ã‚ºã¨oã‚·ãƒªãƒ¼ã‚ºã‚’çµ±åˆ",
        "category": "æœ€å¼·ãƒ¢ãƒ‡ãƒ«"
    },
    "GPT-5 Mini (è»½é‡ç‰ˆ)": {
        "id": "gpt-5-mini",
        "description": "GPT-5ã®è»½é‡ç‰ˆã€‚é«˜é€Ÿå‡¦ç†ã¨ã‚³ã‚¹ãƒˆåŠ¹ç‡ã‚’é‡è¦–ã—ãŸãƒ¢ãƒ‡ãƒ«",
        "category": "æœ€å¼·ãƒ¢ãƒ‡ãƒ«"
    },
    "GPT-5 Chat (å¯¾è©±ç‰¹åŒ–)": {
        "id": "gpt-5-chat",
        "description": "å¯¾è©±å‹ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å‘ã‘ã«æœ€é©åŒ–ã•ã‚ŒãŸGPT-5ãƒ¢ãƒ‡ãƒ«",
        "category": "æœ€å¼·ãƒ¢ãƒ‡ãƒ«"
    },
    "GPT-4o (ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«)": {
        "id": "gpt-4o",
        "description": "ãƒ†ã‚­ã‚¹ãƒˆã€ç”»åƒã€éŸ³å£°ã®çµ±åˆå‡¦ç†ãŒå¯èƒ½ãªãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«",
        "category": "æœ€æ–°ãƒ¢ãƒ‡ãƒ«"
    },
    "o1-mini (æ¨è«–ç‰¹åŒ–)": {
        "id": "o1-mini",
        "description": "æ¨è«–èƒ½åŠ›ã«ç‰¹åŒ–ã—ãŸãƒ¢ãƒ‡ãƒ«ã€‚æ•°å­¦ã‚„ç§‘å­¦ã®å•é¡Œè§£æ±ºã«å„ªã‚Œã‚‹",
        "category": "æ¨è«–ç‰¹åŒ–"
    },
    "GPT-4-turbo (é«˜æ€§èƒ½)": {
        "id": "gpt-4-turbo",
        "description": "GPT-4ã®é«˜æ€§èƒ½ç‰ˆã€‚è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã«å„ªã‚ŒãŸæ€§èƒ½ã‚’ç™ºæ®",
        "category": "é«˜æ€§èƒ½"
    },
    "GPT-3.5-turbo (å¾“æ¥å‹)": {
        "id": "gpt-3.5-turbo",
        "description": "å®‰å®šã—ãŸæ€§èƒ½ã¨ã‚³ã‚¹ãƒˆåŠ¹ç‡ã‚’æä¾›ã™ã‚‹å¾“æ¥å‹ãƒ¢ãƒ‡ãƒ«",
        "category": "å¾“æ¥å‹"
    }
}

def main():
    # ã‚¿ã‚¤ãƒˆãƒ«
    st.title("ğŸ¤– æœ€æ–°AIãƒãƒ£ãƒƒãƒˆã‚¢ãƒ—ãƒª")
    st.markdown("---")
    
    # ãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è¡¨ç¤ºã‚’æ”¹å–„ã™ã‚‹CSS
    st.markdown("""
    <style>
    /* å…¨ä½“ã®ã‚³ãƒ³ãƒ†ãƒŠè¨­å®š */
    .main .block-container {
        max-width: 100% !important;
        padding-left: 0.25rem !important;
        padding-right: 0.25rem !important;
        margin: 0 !important;
    }
    
    /* ãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å…¨ä½“ã®è¨­å®š */
    .stChatMessage {
        word-wrap: break-word !important;
        white-space: pre-wrap !important;
        overflow-wrap: break-word !important;
        max-width: 100% !important;
        overflow: visible !important;
        word-break: break-word !important;
        width: 100% !important;
        box-sizing: border-box !important;
        margin: 0 !important;
        padding: 0.5rem !important;
    }
    
    /* ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚³ãƒ³ãƒ†ãƒŠã®è¨­å®š */
    .stChatMessage .stMarkdown {
        word-wrap: break-word !important;
        white-space: pre-wrap !important;
        overflow-wrap: break-word !important;
        max-width: 100% !important;
        overflow: visible !important;
        word-break: break-word !important;
        width: 100% !important;
        box-sizing: border-box !important;
        margin: 0 !important;
        padding: 0 !important;
    }
    
    /* æ®µè½ã®è¨­å®š */
    .stChatMessage .stMarkdown p {
        word-wrap: break-word !important;
        white-space: pre-wrap !important;
        overflow-wrap: break-word !important;
        max-width: 100% !important;
        overflow: visible !important;
        word-break: break-word !important;
        margin: 0 !important;
        padding: 0 !important;
        width: 100% !important;
        box-sizing: border-box !important;
    }
    
    /* ãƒãƒ£ãƒƒãƒˆã‚³ãƒ³ãƒ†ãƒŠã®è¨­å®š */
    .stChatMessageContainer {
        max-width: 100% !important;
        overflow: visible !important;
        width: 100% !important;
        box-sizing: border-box !important;
        margin: 0 !important;
        padding: 0 !important;
    }
    
    /* ãƒãƒ£ãƒƒãƒˆå…¥åŠ›ã‚¨ãƒªã‚¢ã®è¨­å®š */
    .stChatInput {
        max-width: 100% !important;
        width: 100% !important;
    }
    
    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®è¨­å®š */
    .stSidebar {
        max-width: 20% !important;
    }
    
    /* ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢ã®è¨­å®š */
    .main .block-container > div {
        max-width: 100% !important;
        width: 100% !important;
        margin: 0 !important;
        padding: 0 !important;
    }
    
    /* ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã®è¨­å®š */
    .stChatMessage pre {
        word-wrap: break-word !important;
        white-space: pre-wrap !important;
        overflow-wrap: break-word !important;
        max-width: 100% !important;
        overflow: visible !important;
        word-break: break-word !important;
        width: 100% !important;
        box-sizing: border-box !important;
    }
    
    /* ã™ã¹ã¦ã®ãƒ†ã‚­ã‚¹ãƒˆè¦ç´  */
    .stChatMessage * {
        word-wrap: break-word !important;
        overflow-wrap: break-word !important;
        word-break: break-word !important;
        max-width: 100% !important;
        overflow: visible !important;
    }
    </style>
    """, unsafe_allow_html=True)

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ãƒ¢ãƒ‡ãƒ«é¸æŠ
    with st.sidebar:
        st.header("âš™ï¸ ãƒ¢ãƒ‡ãƒ«è¨­å®š")
        
        # ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ¢ãƒ‡ãƒ«é¸æŠ
        model_options = list(MODELS.keys())
        selected_model_name = st.selectbox(
        "ä¼šè©±ã«ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„",
            model_options,
            index=0,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§GPT-5ã‚’é¸æŠ
            help="å„ãƒ¢ãƒ‡ãƒ«ã®ç‰¹å¾´ã‚’ç¢ºèªã—ã¦ã‹ã‚‰é¸æŠã—ã¦ãã ã•ã„"
        )
        
        selected_model = MODELS[selected_model_name]
        
        # ãƒ¢ãƒ‡ãƒ«æƒ…å ±è¡¨ç¤º
        st.markdown("---")
        st.subheader("ğŸ“‹ é¸æŠä¸­ã®ãƒ¢ãƒ‡ãƒ«")
        st.info(f"**{selected_model_name}**\n\n{selected_model['description']}")
        
        # è¿½åŠ è¨­å®š
        st.markdown("---")
        st.subheader("ğŸ”§ è¿½åŠ è¨­å®š")
        
        # GPT-5ç³»ã§ã¯temperatureã‚’å›ºå®šå€¤ã«
        if selected_model["id"].startswith("gpt-5"):
            st.info("ğŸ¤– GPT-5ç³»ã§ã¯å‰µé€ æ€§ã¯å›ºå®šå€¤(1.0)ã§ã™")
            temperature = 1.0
        else:
            temperature = st.slider("å‰µé€ æ€§ (Temperature)", 0.0, 2.0, 0.7, 0.1)
        
        max_tokens = st.slider("æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°", 100, 4000, 1000, 100)

    # ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢
    st.subheader("ğŸ’¬ ãƒãƒ£ãƒƒãƒˆ")

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å®Œå…¨ã«è¡¨ç¤º
            content = message["content"]
            
            # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¤‡æ•°ã®æ–¹æ³•ã§è¡¨ç¤ºï¼ˆç¢ºå®Ÿã«å®Œå…¨è¡¨ç¤ºï¼‰
            st.markdown(content)
            
            # ã™ã¹ã¦ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«ãƒ—ãƒ¬ãƒ¼ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¤ºã‚’è¿½åŠ ï¼ˆç¢ºå®Ÿã«å®Œå…¨è¡¨ç¤ºï¼‰
            with st.expander("ğŸ“„ å®Œå…¨ãªãƒ†ã‚­ã‚¹ãƒˆã‚’è¡¨ç¤º", expanded=False):
                st.text(content)
                # ã•ã‚‰ã«ç¢ºå®Ÿã«ã™ã‚‹ãŸã‚ã€ç”Ÿã®ãƒ†ã‚­ã‚¹ãƒˆã‚‚è¡¨ç¤º
                st.code(content, language=None)
            
            if message["role"] == "assistant":
                # ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’è¡¨ç¤º
                model_info = message.get("model_info", "")
                if model_info:
                    st.caption(f"ğŸ¤– {model_info}")

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›
    if prompt := st.chat_input("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„..."):
        # å…¥åŠ›ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ä»˜ä¸
        st.session_state.messages.append({
            "role": "user",
            "content": prompt,
            "ts": int(time.time())
        })
        with st.chat_message("user"):
            st.markdown(prompt)

        # OpenAI APIã‚’ä½¿ç”¨ã—ã¦å¿œç­”ã‚’ç”Ÿæˆ
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            full_response = ""
            
            try:
                # ãƒ¢ãƒ‡ãƒ«å›ºæœ‰ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
                api_params = {
                    "model": selected_model["id"],
                    "messages": [
                    {"role": m["role"], "content": m["content"]}
                    for m in st.session_state.messages
                ],
                }
                
                # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¨­å®š
                api_params["stream"] = True
                
                # ãƒ¢ãƒ‡ãƒ«å›ºæœ‰ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
                if selected_model["id"].startswith("o1"):
                    # o1ç³»ã¯temperatureã¨max_tokensã‚’è¨­å®šã—ãªã„
                    pass
                elif selected_model["id"].startswith("gpt-5"):
                    # GPT-5ç³»ã¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åˆ¶é™ã‚ã‚Š
                    api_params["temperature"] = 1.0
                    api_params["max_completion_tokens"] = max_tokens
                else:
                    # ãã®ä»–ã®ãƒ¢ãƒ‡ãƒ«ã¯å¾“æ¥é€šã‚Š
                    api_params["temperature"] = temperature
                    api_params["max_tokens"] = max_tokens
                
                # APIå‘¼ã³å‡ºã—
                response_stream = client.chat.completions.create(**api_params)
                
                for response in response_stream:
                    if response.choices[0].delta.content:
                        full_response += response.choices[0].delta.content
                message_placeholder.markdown(full_response + "â–Œ")
                
                message_placeholder.markdown(full_response)
                
                # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«ãƒ¢ãƒ‡ãƒ«æƒ…å ±ãƒ»åˆ©ç”¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ»ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’è¿½åŠ 
                used_params = {
                    "model": selected_model["id"],
                    # GPT-5ç³»ã¯max_completion_tokensã€ãã‚Œä»¥å¤–ã¯max_tokensã‚’æ¡ç”¨
                    "temperature": 1.0 if selected_model["id"].startswith("gpt-5") else (
                        None if selected_model["id"].startswith("o1") else temperature
                    ),
                    "max_tokens": None if selected_model["id"].startswith("gpt-5") else (
                        None if selected_model["id"].startswith("o1") else max_tokens
                    ),
                    "max_completion_tokens": max_tokens if selected_model["id"].startswith("gpt-5") else None,
                }

                st.session_state.messages.append({
                    "role": "assistant",
                    "content": full_response,
                    "model_info": selected_model_name,
                    "params": used_params,
                    "ts": int(time.time())
                })
                
            except Exception as e:
                error_msg = f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
                message_placeholder.error(error_msg)
                
                # ãƒ¢ãƒ‡ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã®ç‰¹åˆ¥ãªå‡¦ç†
                if "does not exist" in str(e) or "model_not_found" in str(e):
                    st.warning(f"âš ï¸ ãƒ¢ãƒ‡ãƒ« '{selected_model['id']}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚åˆ¥ã®ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
                    st.info("ğŸ’¡ æ¨å¥¨ãƒ¢ãƒ‡ãƒ«: GPT-4o, GPT-4o-mini, o1-mini, GPT-4-turbo, GPT-3.5-turbo")
                elif "rate_limit" in str(e).lower():
                    st.warning("âš ï¸ ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚ã—ã°ã‚‰ãå¾…ã£ã¦ã‹ã‚‰å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚")
                elif "insufficient_quota" in str(e).lower():
                    st.warning("âš ï¸ APIã‚¯ã‚©ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚ã‚¢ã‚«ã‚¦ãƒ³ãƒˆè¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": error_msg,
                    "model_info": selected_model_name,
                    "params": {"model": selected_model["id"]},
                    "ts": int(time.time())
                })

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ç®¡ç†
    if st.session_state.messages:
        col1, col2 = st.columns([1, 1])
        with col1:
            if st.button("ğŸ—‘ï¸ å±¥æ­´ã‚’ã‚¯ãƒªã‚¢"):
                st.session_state.messages = []
                st.rerun()
        with col2:
            if st.button("ğŸ’¾ å±¥æ­´ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"):
                # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå½¢å¼é¸æŠã‚’è¡¨ç¤º
                export_format = st.selectbox("ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå½¢å¼", ["CSV", "JSONL"], index=0, key="export_format")
                
                if export_format == "CSV":
                    # æ¯”è¼ƒã—ã‚„ã™ã„ç¸¦æŒã¡CSV: index,ts,role,model,temperature,max_tokens,max_completion_tokens,content
                    import csv
                    from io import StringIO
                    buffer = StringIO()
                    writer = csv.writer(buffer)
                    writer.writerow(["index", "ts", "role", "model", "temperature", "max_tokens", "max_completion_tokens", "content"])
                    for i, msg in enumerate(st.session_state.messages):
                        params = msg.get("params", {})
                        model = params.get("model", msg.get("model_info", ""))
                        writer.writerow([
                            i,
                            msg.get("ts", ""),
                            msg.get("role", ""),
                            model,
                            params.get("temperature", ""),
                            params.get("max_tokens", ""),
                            params.get("max_completion_tokens", ""),
                            msg.get("content", "").replace("\n", " ")
                        ])
                    data = buffer.getvalue()
                    st.download_button(
                        label="ğŸ“¥ CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=data,
                        file_name=f"chat_history_{int(time.time())}.csv",
                        mime="text/csv"
                    )
                else:
                    # JSONL: 1è¡Œ1ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆæ¯”è¼ƒã®ãŸã‚ã®å®Œå…¨æƒ…å ±ï¼‰
                    import json
                    lines = []
                    for i, msg in enumerate(st.session_state.messages):
                        record = {
                            "index": i,
                            "ts": msg.get("ts"),
                            "role": msg.get("role"),
                            "model_info": msg.get("model_info"),
                            "params": msg.get("params"),
                            "content": msg.get("content"),
                        }
                        lines.append(json.dumps(record, ensure_ascii=False))
                    data = "\n".join(lines)
                    st.download_button(
                        label="ğŸ“¥ JSONLãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=data,
                        file_name=f"chat_history_{int(time.time())}.jsonl",
                        mime="application/jsonl"
                    )

# ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒç›´æ¥å®Ÿè¡Œã•ã‚ŒãŸå ´åˆã«mainã‚’å‘¼ã³å‡ºã™
if __name__ == "__main__":
    main()
