import streamlit as st
from openai import OpenAI
import time

# ==========================
#  OpenAI APIã‚­ãƒ¼ã®è¨­å®š
# ==========================
client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])  # ã“ã“ã«OpenAIã®APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„

# ==========================
#  ãƒ¢ãƒ‡ãƒ«è¨­å®š
# ==========================
MODELS = {
    "GPT-5 (æœ€å¼·ãƒ»çµ±åˆå‹)": {
        "id": "gpt-5",
        "description": "2025å¹´8æœˆãƒªãƒªãƒ¼ã‚¹ã®æœ€å¼·ãƒ¢ãƒ‡ãƒ«ã€‚GPTã‚·ãƒªãƒ¼ã‚ºã¨oã‚·ãƒªãƒ¼ã‚ºã‚’çµ±åˆã—ã€æ¨è«–èƒ½åŠ›ã¨ã‚³ãƒ¼ãƒ‰ç”Ÿæˆèƒ½åŠ›ãŒå¤§å¹…å‘ä¸Š",
        "category": "æœ€å¼·ãƒ¢ãƒ‡ãƒ«"
    },
    "GPT-5 Standard (æ¨™æº–ç‰ˆ)": {
        "id": "gpt-5-standard",
        "description": "GPT-5ã®æ¨™æº–ç‰ˆã€‚ä¸€èˆ¬çš„ãªç”¨é€”å‘ã‘ã«æœ€é©åŒ–ã•ã‚ŒãŸãƒãƒ©ãƒ³ã‚¹å‹ãƒ¢ãƒ‡ãƒ«",
        "category": "æœ€å¼·ãƒ¢ãƒ‡ãƒ«"
    },
    "GPT-5 Mini (è»½é‡ç‰ˆ)": {
        "id": "gpt-5-mini",
        "description": "GPT-5ã®è»½é‡ç‰ˆã€‚é«˜é€Ÿå‡¦ç†ã¨ã‚³ã‚¹ãƒˆåŠ¹ç‡ã‚’é‡è¦–ã—ãŸãƒ¢ãƒ‡ãƒ«",
        "category": "æœ€å¼·ãƒ¢ãƒ‡ãƒ«"
    },
    "GPT-5 Nano (è¶…è»½é‡ç‰ˆ)": {
        "id": "gpt-5-nano",
        "description": "GPT-5ã®è¶…è»½é‡ç‰ˆã€‚ãƒªã‚½ãƒ¼ã‚¹ãŒé™ã‚‰ã‚ŒãŸç’°å¢ƒã§ã®ä½¿ç”¨ã«æœ€é©",
        "category": "æœ€å¼·ãƒ¢ãƒ‡ãƒ«"
    },
    "GPT-5 Chat (å¯¾è©±ç‰¹åŒ–)": {
        "id": "gpt-5-chat",
        "description": "å¯¾è©±å‹ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å‘ã‘ã«æœ€é©åŒ–ã•ã‚ŒãŸGPT-5ãƒ¢ãƒ‡ãƒ«",
        "category": "æœ€å¼·ãƒ¢ãƒ‡ãƒ«"
    },
    "GPT-4.1 (é«˜æ€§èƒ½)": {
        "id": "gpt-4.1",
        "description": "2025å¹´4æœˆãƒªãƒªãƒ¼ã‚¹ã®é«˜æ€§èƒ½ãƒ¢ãƒ‡ãƒ«ã€‚ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°èƒ½åŠ›ã¨æŒ‡ç¤ºç†è§£èƒ½åŠ›ãŒå‘ä¸Š",
        "category": "æœ€æ–°ãƒ¢ãƒ‡ãƒ«"
    },
    "GPT-4o (ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«)": {
        "id": "gpt-4o",
        "description": "ãƒ†ã‚­ã‚¹ãƒˆã€ç”»åƒã€éŸ³å£°ã®çµ±åˆå‡¦ç†ãŒå¯èƒ½ãªãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«",
        "category": "ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«"
    },
    "GPT-4o-mini (é«˜é€Ÿãƒ»è»½é‡)": {
        "id": "gpt-4o-mini",
        "description": "GPT-4oã®è»½é‡ç‰ˆã€‚é«˜é€Ÿãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¨ã‚³ã‚¹ãƒˆåŠ¹ç‡ã‚’é‡è¦–",
        "category": "è»½é‡ãƒ¢ãƒ‡ãƒ«"
    },
    "o1-preview (æ¨è«–ç‰¹åŒ–)": {
        "id": "o1-preview",
        "description": "è¤‡é›‘ãªæ¨è«–ã‚¿ã‚¹ã‚¯ã«ç‰¹åŒ–ã—ãŸãƒ¢ãƒ‡ãƒ«ã€‚æ•°å­¦ã‚„ç§‘å­¦ã®å•é¡Œè§£æ±ºã«å„ªã‚Œã‚‹",
        "category": "æ¨è«–ç‰¹åŒ–"
    },
    "o1-mini (æ¨è«–è»½é‡)": {
        "id": "o1-mini",
        "description": "o1ã®è»½é‡ç‰ˆã€‚æ¨è«–èƒ½åŠ›ã‚’ä¿ã¡ãªãŒã‚‰é«˜é€Ÿãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å®Ÿç¾",
        "category": "æ¨è«–ç‰¹åŒ–"
    },
    "o3-mini (æ¬¡ä¸–ä»£æ¨è«–)": {
        "id": "o3-mini",
        "description": "2025å¹´1æœˆãƒªãƒªãƒ¼ã‚¹ã€‚æ¨è«–èƒ½åŠ›ãŒã•ã‚‰ã«å¼·åŒ–ã•ã‚ŒãŸæ¬¡ä¸–ä»£ãƒ¢ãƒ‡ãƒ«",
        "category": "æ¬¡ä¸–ä»£æ¨è«–"
    },
    "GPT-3.5-turbo (å¾“æ¥å‹)": {
        "id": "gpt-3.5-turbo",
        "description": "å®‰å®šã—ãŸæ€§èƒ½ã¨ã‚³ã‚¹ãƒˆåŠ¹ç‡ã‚’æä¾›ã™ã‚‹å¾“æ¥å‹ãƒ¢ãƒ‡ãƒ«",
        "category": "å¾“æ¥å‹"
    }
}

def main():
    # ã‚¿ã‚¤ãƒˆãƒ«
    st.title("ğŸ¤– æœ€æ–°AIãƒãƒ£ãƒƒãƒˆã‚¢ãƒ—ãƒª")
    st.markdown("---")

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ãƒ¢ãƒ‡ãƒ«é¸æŠ
    with st.sidebar:
        st.header("âš™ï¸ ãƒ¢ãƒ‡ãƒ«è¨­å®š")
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«ãƒ¢ãƒ‡ãƒ«ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        categories = {}
        for name, info in MODELS.items():
            category = info["category"]
            if category not in categories:
                categories[category] = []
            categories[category].append((name, info))
        
        # ã‚«ãƒ†ã‚´ãƒªã”ã¨ã«ãƒ¢ãƒ‡ãƒ«ã‚’è¡¨ç¤º
        selected_model_name = None
        for category, models in categories.items():
            st.subheader(f"ğŸ“ {category}")
            for name, info in models:
                if st.radio(
                    name,
                    [name],
                    key=f"model_{name}",
                    help=info["description"]
                ):
                    selected_model_name = name
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆé¸æŠ
        if not selected_model_name:
            selected_model_name = "GPT-5 (æœ€å¼·ãƒ»çµ±åˆå‹)"
        
        selected_model = MODELS[selected_model_name]
        
        # ãƒ¢ãƒ‡ãƒ«æƒ…å ±è¡¨ç¤º
        st.markdown("---")
        st.subheader("ğŸ“‹ é¸æŠä¸­ã®ãƒ¢ãƒ‡ãƒ«")
        st.info(f"**{selected_model_name}**\n\n{selected_model['description']}")
        
        # è¿½åŠ è¨­å®š
        st.markdown("---")
        st.subheader("ğŸ”§ è¿½åŠ è¨­å®š")
        temperature = st.slider("å‰µé€ æ€§ (Temperature)", 0.0, 2.0, 0.7, 0.1)
        max_tokens = st.slider("æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°", 100, 4000, 1000, 100)

    # ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢
    st.subheader("ğŸ’¬ ãƒãƒ£ãƒƒãƒˆ")

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "current_model" not in st.session_state:
        st.session_state.current_model = selected_model_name

    # ãƒ¢ãƒ‡ãƒ«å¤‰æ›´æ™‚ã®å±¥æ­´ã‚¯ãƒªã‚¢ç¢ºèª
    if st.session_state.current_model != selected_model_name:
        if st.button("ğŸ”„ ãƒ¢ãƒ‡ãƒ«ã‚’å¤‰æ›´ï¼ˆå±¥æ­´ã‚’ã‚¯ãƒªã‚¢ï¼‰"):
            st.session_state.messages = []
            st.session_state.current_model = selected_model_name
            st.rerun()

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            if message["role"] == "assistant":
                # ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’è¡¨ç¤º
                model_info = message.get("model_info", "")
                if model_info:
                    st.caption(f"ğŸ¤– {model_info}")

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›
    if prompt := st.chat_input("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # OpenAI APIã‚’ä½¿ç”¨ã—ã¦å¿œç­”ã‚’ç”Ÿæˆ
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            full_response = ""
            
            try:
                # ãƒ¢ãƒ‡ãƒ«å›ºæœ‰ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
                api_params = {
                    "model": selected_model["id"],
                    "messages": [
                        {"role": m["role"], "content": m["content"]}
                        for m in st.session_state.messages
                    ],
                    "stream": True,
                }
                
                # o1ç³»ã€o3ç³»ã€GPT-5ç³»ã¯temperatureã¨max_tokensã‚’è¨­å®šã—ãªã„
                if not (selected_model["id"].startswith("o1") or 
                        selected_model["id"].startswith("o3") or 
                        selected_model["id"].startswith("gpt-5")):
                    api_params["temperature"] = temperature
                    api_params["max_tokens"] = max_tokens
                
                # APIå‘¼ã³å‡ºã—
                for response in client.chat.completions.create(**api_params):
                    if response.choices[0].delta.content:
                        full_response += response.choices[0].delta.content
                        message_placeholder.markdown(full_response + "â–Œ")
                
                message_placeholder.markdown(full_response)
                
                # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’è¿½åŠ 
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": full_response,
                    "model_info": selected_model_name
                })
                
            except Exception as e:
                error_msg = f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
                message_placeholder.error(error_msg)
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": error_msg,
                    "model_info": selected_model_name
                })

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ç®¡ç†
    if st.session_state.messages:
        col1, col2 = st.columns([1, 1])
        with col1:
            if st.button("ğŸ—‘ï¸ å±¥æ­´ã‚’ã‚¯ãƒªã‚¢"):
                st.session_state.messages = []
                st.rerun()
        with col2:
            if st.button("ğŸ’¾ å±¥æ­´ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"):
                # å±¥æ­´ã‚’ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
                export_text = ""
                for msg in st.session_state.messages:
                    role = "ãƒ¦ãƒ¼ã‚¶ãƒ¼" if msg["role"] == "user" else "ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ"
                    export_text += f"{role}: {msg['content']}\n\n"
                
                st.download_button(
                    label="ğŸ“¥ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=export_text,
                    file_name=f"chat_history_{int(time.time())}.txt",
                    mime="text/plain"
                )

# ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒç›´æ¥å®Ÿè¡Œã•ã‚ŒãŸå ´åˆã«mainã‚’å‘¼ã³å‡ºã™
if __name__ == "__main__":
    main()
